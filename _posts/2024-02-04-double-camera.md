---
layout: post
title:  "カメラ付きプラレールの通信プロトコルを解析した話"
---

# カメラ付きプラレールの通信プロトコルを解析した話
先日押し入れを整理していたところ、カメラの付いたドクターイエローのプラレールを発掘しました。

（ドクターイエローの写真）

こちらは[スマホで運転！ダブルカメラドクターイエロー](https://www.takaratomy.co.jp/products/plarail/tettei/set/16_09_pte/index.htm)という商品で、
名前の通りカメラが付いていてスマートホンから操作できるプラレールの電車です。
2016年10月にタカラトミーより発売されました。

私の手元にあるものは風穴さん ([@windhole](https://twitter.com/windhole)) から頂いたものでした。
私がプラレールで半加算器や全加算器を作っていた頃に面白いものがあるからと贈っていただいた記憶があります。

さて、昔のことを思い出しながらiPadに入っていた専用アプリで久々に遊んでみます。
アプリから電車の速度を変えられたり、車両に付いているカメラの映像を表示できたりとなかなか高機能でよくできたおもちゃです。
カメラはリアルタイムで先頭車両・車窓の2つが切り替えられるようになっていて凝った作りになっています。

（アプリの写真）

しかし残念ながらアプリの配信自体はすでに2022年までで終了しており、
中古などで手に入れた人はもう遊べないという状況になっていました。
そこで制御プロトコルを解析して、専用アプリ以外からもこのドクターイエローを制御できないか？と思い試すことにしました。

本記事ではその記録と得られた結果、および試行錯誤に使ったツールや情報をまとめます。
ツールに関してはMacの使用が前提になっていることをあらかじめご了承ください。
また、試行錯誤の過程を思い出しながら書いているためぐだぐだかもしれませんがそこもご容赦ください。

## 仕組み
専用アプリからどうやってドクターイエローに繋いでいるのでしょうか？
一言で言えば、ドクターイエローがWi-Fiの母艦になっており、
スマホなどの端末からそこに接続することで専用アプリとドクターイエローの通信ができる、という仕組みになっています。

（システム構成図みたいなのを出す）

というわけで、まずはWi-Fiの通信を傍受すれば制御プロトコルがわかるのではないか？と考えて先に進むことにしました。

## Macでのパケットキャプチャがうまくいかない？！
真っ先に思いつくことはWi-Fiのパケットキャプチャですよね。
Macではワイヤレス診断.app というアプリケーションの機能としてWi-Fiスニファがあるのでそれを利用することにしました。
これを使うことで、Macが直接関わらないWi-Fiの通信も傍受することができます。
まず、前もってプラレールのWi-FiにMacから接続し、Wi-Fiアクセスポイントとしての情報を確かめてみます。

（画像、Wi-Fiのやつ）

モバイル端末からだけではなく、Macからも接続できました。どうやら2.4GHz帯のチャネル1、チャネル幅は20MHzのようです。
この情報を元にWi-Fiスニファを使用します。
ワイヤレス診断.appのウィンドウ > スニファを選択するとチャネルとチャネル幅を選ぶダイアログが表示されるので、上記の情報を入力しスニファを実行します。
（その間、MacのWi-Fi機能は使えなくなります）

結果は `/var/tmp` ディレクトリに保存されるのですが...... なんとサイズが0バイトとなり、中身がありませんでした（滝汗）
試しにチャネル2に対してスニファを実行したらうまく保存できたので、チャネル1に対してはなんらかの制約があるのかもしれません。
（ご存知の方がいらっしゃったら教えていただけると嬉しいです）

Linuxなどの別の端末で行うことも考えましたが、やや大変そうだったためパケットの空気録音はあきらめることにしました。

## Macで接続した際の挙動
MacからドクターイエローのWi-Fiに繋いだ際には、DHCPが有効になっており、降ってきたIPアドレスは `192.168.123.2` で、ゲートウェイは `192.168.123.1` でした。
試しにこのIPアドレスに対して ping を飛ばしたところ予想通り返ってきました。
複雑なことをしているとも思えないので `192.168.123.1` に何かしらを行えばドクターイエローの制御ができると思われます。

次にやることといったらポートスキャンでしょうか。
開いているTCPポートを探すことにしました。
`nmap` コマンドを試してみましたが、反応はなかったので次はどうしようかという感じになりました。

## 専用アプリを騙してMacにつなげる
今回捕捉したい通信は専用アプリからドクターイエローへの命令なのですが、
Wi-Fiの傍受がうまくいかないことから別の手段を講じる必要がありました。
少々考えたところ、 **MacのIPアドレスを 192.168.123.1 にして** 同じネットワークに接続すればアプリから繋ぎに来てくれるのでは？と予想しました。

（ルーター越しに繋がっている図）

自宅で使っているのがTP-Linkの普通のルーターでしたが、DHCPのアドレス予約機能を使うことでMacに対して `192.168.123.1` を割り当てることができました。
その際に、サブネットマスクを `255.255.255.0` から `255.255.0.0` に変更する必要がありました。

この状況でWiresharkでパケットキャプチャを開始し、アプリでの操作を行うと... 出ました、
`192.168.123.1` への**UDP**の通信です。

（スキャン結果）

UDPとは盲点でした。ポートスキャンがうまくいかなかったのも合点が行きます。

さて、これで通信の中身は見放題です。パケットキャプチャ中にいろいろな操作をしたところ、
専用アプリは以下の表のような体系でコマンドを送信することが分かりました。

| 操作                   | UDP宛先ポート | ペイロード | ASCII表現 | 備考 |
| --------------------  | ---- | --------- |--- | - |
| 接続確認・設定の取得     | 30863 | `0x42 0x02` | B\x02 | SSID・MACアドレス等 <br> を含むレスポンスが返ってくる |
| 映像配信要求            | 30863 | `0x42 0x76` | Bv | 詳しくは後述 |
| 映像停止要求？          | 30863 | `0x42 0x76` | Bw | あまり確証ないです |
| カメラを車窓に切り替え    | 30864 | `0x42 0x70` | Bp | |
| カメラを運転席に切り替え  | 30864 | `0x42 0x71` | Bq | |
| 高速走行              | 30864 | `0x42 0x72` | Br | |
| バック走行              | 30864 | `0x42 0x73` | Bs | | 
| 低速走行              | 30864 | `0x42 0x74` | Bt | |
| 電車停止              | 30864 | `0x42 0x75` | Bu | |

ひとつ何か実行してみましょう。UDPパケットを送る方法はncコマンドなどいくつかありますが、
一番手軽だと筆者が考えるは bash の擬似デバイスを使う方法です。
ターミナルを開き、電車を走らせるコマンド `0x42 0x74` を送ってみます、動くでしょうか...

```bash
printf 'Bt' > /dev/udp/192.168.123.1/30864
```

（コマンドを打って電車が走るGIF）

やりました、成功です！バック走行や電車の停止などがうまくいくことも確認できました。

さて、次の課題は映像の取得です。

## 映像は謎
カメラが2つもついてるのに運転席からの風景が見れないのはさみしいです。
ここからはどうにかしてドクターイエローからの映像を取得して表示できないかを調査していきました。

パケットキャプチャの結果から、ポート30863番に `0x42 0x76` を送ると
ドクターイエローはポート30865番に映像データを送り始めることは分かっていましたが、肝心の中身はさっぱり分かりません。
ただ、わからないなりにパケットを観察していくうちに以下のような規則性が読み取れました。

- パケットは固定長で1028バイト
- パケットの末尾4バイトには規則性がある（これをマーカーと呼ぶことにします）
- マーカーの後ろ2バイトはパケット間で連番になっており、短い周期でリセットされる
  - 周期や送信時刻を見るに、この数字は映像の1フレーム中のパケット番号を表しているのではないかと推測
- マーカーの先頭2バイトは以下のパターンになっていた
    - `0xFF 0xDA` ... フレームの最初のパケット
    - `0xFF 0xDD` ... フレームの中間のパケット
    - `0x06 0xD9` ... フレームの最後のパケット
- 1フレームあたりのパケット数は可変だったが、ひとつひとつのパケットは必ず1028バイトだった。

マーカーを除くとパケット1つの長さが1024バイト（2の10乗）というキリのいい数字であることから、
データ全体を1024バイトずつに分割したあとマーカーを付与し、固定長のUDPパケットとして送信していると推測しました。
そのため、1フレームあたりの映像データは連番になっているパケットのデータ内容を結合したものだと仮定して進めることにしました。

### 真っ黒な映像をキャプチャしてみる
私自身、映像のコーデックに関する知識は人並みにしかありません。
そのような状況でなんらかの法則を見つけるためには、システムに対して極端な入力を与えた時の挙動を見ることが手掛かりになることが経験上多いです。
極端な入力としてふと思いついたのが、カメラを手で覆って真っ黒な映像を受信することでした。
するとこんな感じのパケットがやってきました。

（Wiresharkでキャプチャしたやつ）

最初のパケットは `e5` から始まり `28 a0 02 8a 00` を繰り返しています。
続くパケットもこのパターンを繰り返しており、全体で1200回繰り返していました。

（それっぽい16進数の図）

また、各フレームに対しては全く同じデータを含むパケット群がやってきました。
つまり、1フレーム目も2フレーム目もその先も、上の図に描いたようなデータがドクターイエローからやってきました。

先頭の `e5` はどういった意味を持つのでしょうか？いまはまだ分かりません。
ただ、ここに来て興味深い規則性を見つけることはができました。
そしてこれをきっかけに映像プロトコルの解析は大きく進むことになります。

### Motion JPEGという説
この話を会社でしたところ、後輩のぱくとまさん ([@pakutoma](https://twitter.com/pakutoma)) から、
カメラモジュールはMotion JPEGで出力することが多いという話を聞きました。
なるほど、Motion JPEG。調べたところ各フレームをJPEGファイル形式で保存するフォーマットのようです。
比較的エンコードの負荷が低いため組み込み用途で使われることが多く、
それぞれのフレームが独立してエンコードされるという特徴があるようでした。

MPEG-4など他のコーデックはフレーム間にデータの依存関係があるものが多いらしいので、
キャプチャした別々のフレームのデータが全く同じになるということはやはりMotion JPEGなのではないか？という目星がつきました。

### パターンでググる
次にやることは何でしょうか？数少ない手掛かりであるところの "28 a0 02 8a 00" でとりあえずググってみました。
完全一致を狙うために引用符で囲って検索したところ、次のようなページがヒットしました。

- https://gist.github.com/tomvdb/3770f3385faaa3220c7d5d2aadee13ae
- https://gstreamer-bugs.narkive.com/dysVZeiz/bug-763745-new-can-not-decode-jpeg-without-huffman-tables

どちらもJPEGファイルのダンプを掲載したページのようです。
これによってドクターイエローからの映像がJPEG形式で圧縮されているという確証がかなり高まりました。
ここから先はデータがJPEG圧縮されていると仮定して進めていきました。


## JPEGファイルの構造
映像データ復元のため、JPEGファイルのフォーマットについて調査しました。

JPEGファイルのデコードには色空間の変換や離散コサイン変換などたくさんの工程が関わります。
その中でも、量子化（の復元）およびハフマン符号のデコードには画像データそのものの他に、
それぞれの処理のために量子化テーブルおよびハフマンテーブルが必須です。

こういったテーブルは画像ファイル内では共通ですが、画像ごとに異なるものが埋め込まれています。
そのため、JPEGファイルをデコードするためには、ファイル内の画像データとは別の領域に格納する必要があります。

（すっごい雑なJPEGのフォーマットの説明）

また、JPEGファイルは先頭・末尾のマーカー、画像データ、そしていくつかの*セグメント*から構成されます。
マーカーは固定のバイト列、画像データはさまざまな工程を経てエンコードされたデータです。
そしてセグメントは以下のような種類があります。

- 量子化テーブル (DQT)
- ハフマンテーブル (DHT)
- フレームヘッダー (SOF)
  - 画像の大きさなど、JPEGファイルを構成するのに必要な情報を持つ
- スキャンヘッダー (SOS)
  - 画像データの開始を表し、これより後に続く画像データに必要な情報を持つ

他にもアプリケーションデータの保存に使われるセグメントや、
注釈（コメント）を保存するためのセグメントなどがありますが、
今回の登場人物は上の4種類のセグメントです。

それぞれのセグメントの開始は量子化テーブルなら `0xFF 0xDB`、
ハフマンテーブルなら `0xFF 0xC4` のように `0xFF` から始まる2バイトで開始します。

## 本当にJPEGなのか？

さて、この知識を踏まえて映像パケットのデータを見てみましょう。

（図）

何もない！！！！
何もないじゃないですか。
しかしわずかな希望があります。1フレームの最後のパケットには `0xFF 0x09` が現れています。
これはJPEGファイルの終わりを表すマーカー（EOI）に他なりません。

真っ黒な映像以外のフレームについてもパケットを覗いてみましたが、
フレームの最後のパケットにはEOIが含まれていました。
JPEGという読みは間違っていないような気がします。

とはいえパターンが連続するため、EOIの直前までは画像データが続いているように思えます。
ここに至って最後の仮説が出てきます。
すなわち、パケットのデータは量子化テーブルやハフマンテーブルを除いた画像データのみなのではないか？
というやつです。ドクターイエローにも専用アプリにも同じテーブルを用意し、
映像のフレームを転送する際にそれらだけを省いて送信しているのではないかと予想します。

さて、この仮説を検証していきましょう。

## そもそもどんなテーブルを使っているのか？
JPEGの仕様である ITU-T勧告T.81には付録として標準的な量子化テーブルとハフマンテーブルが記載されています。とりあえずこれを使ってデコードができるか試してみることにします。

やることは比較的単純で、SOIマーカーから始まるJPEGに必要な量子化テーブルやハフマンテーブル、それにフレームヘッダーやスキャンヘッダーの先頭部分だけを作成し、ドクターイエローからやってきた映像のフレームと結合すればJPEGファイルとして認識されるのではないか？と考えました。

というわけでそのJPEGファイルの "頭" の部分を作るわけですが、各種テーブルを自前で作成するのは骨が折れます。
ここはオープンソースで公開されているソフトウェアを利用させてもらいます。

JPEG実装の手習として、[libKPEG](https://github.com/TheIllusionistMirage/libKPEG)というものが公開されていたので中を覗いてみると、勧告T.81と同じテーブルを用いてJPEGファイルを作成するコードがあったので結果を利用させてもらうことにしました。

そうして生成したJPEGファイルを見てみると...

（画像、縞模様がなんかでてきたやつ）

なんかおかしいですね... JPEGっぽく認識されてはいるけれど壊れてしまいました。
ここから試行錯誤して適切なテーブルを作ることも考えましたが諦めています。
というのも量子化テーブルは値が変わったとしても画像の見え方が変わるだけだと思いますが、ハフマンテーブルは性質上、圧縮されたデータの切り出し方を定義するため手当たり次第にいじるのは無謀だと考えたためです。

## 録画を抜き出す
万策尽きた... と思いましたがあることを思い出しました。
専用アプリには映像の録画機能があり、iPadにいくつか映像が残されていたことです。
映像の中にJPEGファイルとしてエンコードされたフレームが残っており、そこからテーブルの情報を抜き出せるかもしれません。

さっそくやってみましょう。ただ映像をアプリから取り出す機能が見当たらなかったので、iPadのバックアップから抜き出すことを試みました。

まず、iPadとMacを接続し、端末のバックアップをとります。すると `~/Library/Application Support/MobileSync/Backup/(16進数の識別子)/` にバックアップが保存されます。
このフォルダの中にはiPadに含まれるファイルが保存されており、 `Manifest.db` にiPadのファイルパスとバックアップ内の置き場所の対応が保存されています。
この中に目的となる映像ファイルが入っているはずです。それを探すためにこのファイルを開きます。
`Manifest.db` はSQLite3 のデータベースでした。さっそく中を見てみましょう。

```zsh
% sqlite3 Manifest.db
SQLite version 3.43.2 2023-10-10 13:08:14
Enter ".help" for usage hints.
sqlite> .schema
CREATE TABLE Files (fileID TEXT PRIMARY KEY, domain TEXT, relativePath TEXT, flags INTEGER, file BLOB);
CREATE INDEX FilesDomainIdx ON Files(domain);
CREATE INDEX FilesRelativePathIdx ON Files(relativePath);
CREATE INDEX FilesFlagsIdx ON Files(flags);
CREATE TABLE Properties (key TEXT PRIMARY KEY, value BLOB);
```

`Files` テーブルに対応付が保存されているようです。調べたところ `domain` にiOSのアプリケーション識別子が含まれるようでした。
ダブルカメラドクターイエローの専用アプリに対応する識別子を探します。

```sql
sqlite> select distinct domain from Files;
...
AppDomain-jp.co.taito.groovecoasterzero
AppDomain-jp.co.takaratomy.plaraildoublecamera
AppDomain-jp.klab.lovelive
...
```

どうやら `AppDomain-jp.co.takaratomy.plaraildoublecamera` がそれのようです。
`Files` テーブルの `fileID, relativePath` が怪しそうなので表示してみます。

```sql
sqlite> select fileID, relativePath from Files where domain = "AppDomain-jp.co.takaratomy.plaraildoublecamera";
...
1147223af8e41e77416a77a3125761a872ad9d2d|Documents/Unity/local.2f6b486243079466eb83276e4b7c04f0/Analytics/ArchivedEvents/170687570900002.7afb5f51
83cd78fbdc6f53c56e363a745df05a733bd7e110|Documents/20190623154834.mov
ef0069fe7467333fe10cd25855e75482f87ceee7|Library/Preferences/jp.co.takaratomy.plaraildoublecamera.plist
```

動画ファイルが見当たりました。昔撮影した映像のようです。ファイルIDは `83cd78fbdc6f53c56e363a745df05a733bd7e110` でした。
バックアップフォルダの中に `83/83cd78fbdc6f53c56e363a745df05a733bd7e110` というファイルにあったので、拡張子 `.mov` を付与して開いてみます。

（QuickTime Playerでひらく）

お、Macの標準プレーヤーで開けました。Motion JPEG自体には標準規格がないらしいですが、MOVファイル形式はMotion JPEGをサポートしているらしいです。
気になる中身はどうなってるでしょうか？

（バイナリエディタで hoge.movを開いた内容を出す）

開いたらすぐJPEGのSOIマーカー (`0xFF 0xD8`) が見つかりました。
ここからJPEGファイルが始まるのでしょう。SOIセグメント（画像データの開始）の開始までをコピーし、
パケットキャプチャした映像フレームのデータと結合してみると...？

（復元した画像）

！！！撮影した通りの画像が得られました。これでデコード方法を突き止めることができました。
ちなみに抜き出したJPEGのヘッダに相当するデータの長さは1024バイトでした。キリがいいですね。

あとは実装するだけです。最近仕事でGoを書いているのでGoを使って映像を受信して表示するプログラムを作ってみます。
UDPパケットのサーバは非常に簡単に書けたのと、GUIライブラリは pixel というものを使いました。

（映像を出してるGIFを張る）

長かったですが、これでようやく目的となる映像の受信とデコードができました。
機能は全く充実していませんが、映像受信用のプログラムはこちらで公開しています。
（GitHubへのリンクを貼る）

